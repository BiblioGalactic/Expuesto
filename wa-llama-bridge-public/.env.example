# =========================
# WhatsApp -> llama.cpp bridge (public template)
# =========================

# LLM (OpenAI-compatible endpoint from llama-server)
LLM_BASE_URL=http://127.0.0.1:8080/v1
LLM_MODEL=/absolute/path/to/main-model.gguf
LLM_API_KEY=

# Optional fallback LLM (same machine or another machine)
LLM_FALLBACK_BASE_URL=
LLM_FALLBACK_MODEL=
LLM_FALLBACK_API_KEY=

# Generation
# If SYSTEM_PROMPT_FILE exists, it has priority over SYSTEM_PROMPT.
SYSTEM_PROMPT_FILE=./prompts/prompt_main.txt
SYSTEM_PROMPT=You are a helpful assistant running through WhatsApp.
TEMPERATURE=0.8
MAX_TOKENS=500
REQUEST_TIMEOUT_MS=120000

# Memory (per chat)
HISTORY_TURNS=8
MAX_HISTORY_CHARS=12000

# Routing / safety
# Important: this bridge starts with each chat disabled by default.
# Use /on inside a chat to activate, /off to deactivate.
SELF_CHAT_ONLY=true
ALLOW_GROUPS=false
ALLOW_FROM=+15555550123
IGNORE_OLD_MESSAGES=true

# WhatsApp login mode
# true = login with pairing code (recommended if QR fails)
WA_USE_PAIRING_CODE=true
WA_PAIRING_PHONE=15555550123

# QR mode (only used if WA_USE_PAIRING_CODE=false)
WA_SHOW_QR=false

# Delivery
WA_REPLY_CHUNK_CHARS=1400

# Web scraping
WEB_SCRAPE_ENABLED=true
WEB_SCRAPE_AUTO_URL=false
WEB_SCRAPE_MAX_CHARS=14000
WEB_SCRAPE_TIMEOUT_MS=20000
WEB_SCRAPE_ALLOW_DOMAINS=
WEB_SCRAPE_USER_AGENT=wa-llama-bridge-public/1.0

# Audio transcription API (OpenAI-compatible /v1/audio/transcriptions)
# Keep false unless your endpoint supports STT.
AUDIO_TRANSCRIBE_ENABLED=false
AUDIO_TRANSCRIBE_BASE_URL=
AUDIO_TRANSCRIBE_MODEL=whisper-1
AUDIO_TRANSCRIBE_API_KEY=
AUDIO_TRANSCRIBE_LANGUAGE=es
AUDIO_TRANSCRIBE_PROMPT=
AUDIO_TRANSCRIBE_MAX_MB=20

# Local STT fallback (Python tool + local model)
LOCAL_STT_ENABLED=false
LOCAL_STT_PYTHON=/absolute/path/to/audio_env/bin/python
LOCAL_STT_SCRIPT=./tools/stt_local.py
LOCAL_STT_MODEL_DIR=/absolute/path/to/whisper-model-dir
LOCAL_STT_TASK=transcribe
LOCAL_STT_FORCE_CPU=true
LOCAL_STT_CHUNK_LENGTH_S=30

# Local OCR (PaddleOCR tool)
LOCAL_OCR_ENABLED=false
LOCAL_OCR_PYTHON=/absolute/path/to/ocr_env/bin/python
LOCAL_OCR_SCRIPT=./tools/ocr_local.py
LOCAL_OCR_MODEL_DIR=
LOCAL_OCR_DET_MODEL_NAME=PP-OCRv4_server_det
LOCAL_OCR_REC_MODEL_NAME=PP-OCRv4_server_rec
LOCAL_OCR_CLS_MODEL_NAME=
LOCAL_OCR_DET_MODEL_DIR=/absolute/path/to/PP-OCRv4_server_det
LOCAL_OCR_REC_MODEL_DIR=/absolute/path/to/PP-OCRv4_server_rec
LOCAL_OCR_CLS_MODEL_DIR=
LOCAL_OCR_USE_TEXTLINE_ORIENTATION=false
LOCAL_OCR_LANG=es

# Auto image understanding (OCR + VLM + YOLO -> LLM answer)
AUTO_IMAGE_ANALYZE_ENABLED=false
AUTO_IMAGE_ANALYZE_REQUIRE_OCR=false
AUTO_IMAGE_ANALYZE_MAX_OCR_CHARS=4000
AUTO_IMAGE_ANALYZE_MAX_VLM_CHARS=2500
AUTO_IMAGE_ANALYZE_MAX_YOLO_ITEMS=10

# Local VLM (image-to-text)
LOCAL_VLM_ENABLED=false
LOCAL_VLM_PYTHON=/absolute/path/to/imagen_env/bin/python
LOCAL_VLM_SCRIPT=./tools/vlm_local.py
LOCAL_VLM_MODEL_DIR=/absolute/path/to/VLM-model-dir
LOCAL_VLM_PROMPT=Describe brevemente la imagen en espanol: escena, personas/objetos, accion, contexto y tono.
LOCAL_VLM_MAX_NEW_TOKENS=220
LOCAL_VLM_FORCE_CPU=false
LOCAL_VLM_TIMEOUT_MS=600000

# Local YOLO (object detection)
LOCAL_YOLO_ENABLED=false
LOCAL_YOLO_PYTHON=/absolute/path/to/imagen_env/bin/python
LOCAL_YOLO_SCRIPT=./tools/yolo_local.py
LOCAL_YOLO_MODEL_PATH=/absolute/path/to/yolov8n.pt
LOCAL_YOLO_CONF=0.25
LOCAL_YOLO_IOU=0.45
LOCAL_YOLO_MAX_DET=30
LOCAL_YOLO_TIMEOUT_MS=180000

# Local image generation (Diffusers/SDXL tool)
LOCAL_IMAGE_ENABLED=false
LOCAL_IMAGE_PYTHON=/absolute/path/to/imagen_env/bin/python
LOCAL_IMAGE_SCRIPT=./tools/image_local.py
LOCAL_IMAGE_MODEL_DIR=/absolute/path/to/sdxl-base-model-dir
LOCAL_IMAGE_CHECKPOINT=
LOCAL_IMAGE_STEPS=28
LOCAL_IMAGE_GUIDANCE=6.5
LOCAL_IMAGE_WIDTH=1024
LOCAL_IMAGE_HEIGHT=1024

# Logs: silent | fatal | error | warn | info | debug | trace
LOG_LEVEL=info
